{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab 09 - High Performance Computing\n",
    "#### Module Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mproc, numpy, time"
   ]
  },
  {
   "source": [
    "## Exercise 01 - Number of Processors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of processors: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of processors:\", mproc.cpu_count())"
   ]
  },
  {
   "source": [
    "## Exercise 02 - Array Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(rows, cols, min, max):\n",
    "    return numpy.random.randint(min, max, size=[rows, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_row(row):\n",
    "    COLS = len(row)\n",
    "    norm_row = numpy.zeros(shape=(COLS))\n",
    "    ROW_MIN = min(row)\n",
    "    ROW_MAX = max(row)\n",
    "\n",
    "    for col in range(COLS):\n",
    "        norm_row[col] = (row[col] - ROW_MIN) / (ROW_MAX - ROW_MIN)\n",
    "\n",
    "    return norm_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_by_row(lst):\n",
    "    ROWS, COLS = lst.shape\n",
    "    norm_list = numpy.zeros((ROWS, COLS))\n",
    "\n",
    "    for row in range(ROWS):\n",
    "        norm_list[row] = normalize_row(lst[row][:])\n",
    "\n",
    "    return norm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential normalization by row for size 100 took 0.009999513626098633 seconds\n",
      "Sequential normalization by row for size 500 took 0.13500118255615234 seconds\n",
      "Sequential normalization by row for size 1000 took 0.5070018768310547 seconds\n",
      "Sequential normalization by row for size 2000 took 1.9610047340393066 seconds\n",
      "Sequential normalization by row for size 3000 took 4.421499729156494 seconds\n"
     ]
    }
   ],
   "source": [
    "MIN = 0\n",
    "MAX = 10\n",
    "SIZES = [ 100, 500, 1000, 2000, 3000 ]\n",
    "\n",
    "for size in SIZES:\n",
    "    lst = create_list(size, size, MIN, MAX)\n",
    "    START = time.time()\n",
    "    norm_list = normalize_by_row(lst)\n",
    "    print(\"Sequential normalization by row for size\", size, \"took\", time.time() - START, \"seconds\")"
   ]
  },
  {
   "source": [
    "## Exercise 03 - Parallelization Using pool.apply"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_COUNT = mproc.cpu_count()\n",
    "\n",
    "pool = mproc.Pool(CPU_COUNT)\n",
    "\n",
    "for size in SIZES:\n",
    "    START = time.time()\n",
    "    results = [pool.apply(normalize_row, args=(row,)) for row in lst]\n",
    "    print(\"Parallel normalization by row for size\", size, \"took\", time.time() - START, \"seconds\")\n",
    "\n",
    "pool.close()"
   ]
  }
 ]
}